---
title: Scribing
description: ""
icon: 'otter'
---
    

#### Overview
Automates audio-to-text conversion and structured medical record creation.
#### Inputs
Audio File & JSON Config Input: Users submit audio recordings along with configuration settings to customize processing.
#### Definitions
Recognizing that every doctor has unique scribing needs, our API offers a variety of specialized endpoints designed to accommodate diverse workflows and requirements: <code>Transcription</code>, `Diarized-Transcription`, `Dictation`, `Ambient-Scribing`, `Client-Communications`. Before diving into specific features, it’s important to define key definitions and concepts related to scribing:
- **Transcription:** The process of converting spoken audio into written text verbatim, capturing exactly what was said. This represents the foundational stage of scribing, providing raw text outputs for further refinement.
- **Diarized Transcription:** A more advanced form of transcription that identifies and separates different speakers within the audio. This stage adds structure to the transcription, making it useful for multi-speaker interactions like doctor-client conversations.
- **Dictation:** A focused process where only the doctor’s spoken notes are transcribed, typically to document specific observations or instructions. Dictation moves closer to generating actionable medical content but focuses only on the doctor’s input and generally follows formatting rules expected by the doctor.
- **Ambient Scribing:** A comprehensive approach where the system listens to the full appointment and generates a structured medical note based on the entire conversation. Ambient scribing represents the most advanced stage, synthesizing context and content into a complete medical record.
- **Client Communications:** This can be a section within the medical note, but it is typically referencing the email communication to the client after the completion of the appointment.
#### Outputs
- **Transcription** - audio to text.
- **Diarized Transcription** - identifying differentiate speakers.
- **Dictation** - audio to text following formatting rules of medical note
- **Ambient Scribing** - [Primary Product] audio to medical note following json config
- **Client Communications** -post-visit emails
#### Subsections
Re-querying capabilities, allowing users to submit supplementary audio for further refinement.
#### White-labeling
Interfaces available for both web and mobile platforms, enabling seamless integration into existing workflows.

---

### Scribe Processing Implementation

Below describes how to generate veterinary reports from audio recordings, using a pipeline that includes transcription and parsing steps. The solution involves three main SQS queues, each serving a distinct purpose in the workflow:
- **scribe_v2_transcript_audio_file**
- **scribe_v2_transcript_recording_session**
- **scribe_v2_parse_transcript**

The database schema defines entities such as Recording Sessions, Audio Files, Transcripts, and Templates. Each entity stores information about the transcription process, its status, and how the final report should be parsed and generated.

--- 

#### Data Model (Tables Overview)

- **recording_sessions**
  - Holds information about a recording session initiated by a user (including user ID, name, description).
  - Each session can have multiple audio files attached.

- **recording_session_audio_files**
  - Contains references to the audio file path (likely stored in S3), the ID of the session it belongs to, the transcription status, and a name or title for the audio.
  - May also hold a queue ID and URL if the file is currently in the transcription queue.

- **recording_session_transcripts**
  - Represents the combined transcription of all audio files linked to a session.
  - Stores the ID of the parent session, an optional file path (pointing to consolidated transcripts in S3), and optional queue fields.

- **recording_session_transcript_audio_files (association table)**
  - Many-to-many linkage between transcripts and audio files.
  - Keeps track of which audio files are associated with a given transcript record.

- **recording_session_scribe**
  - Describes the link between a transcript (the final consolidated text) and a parsing template.
  - Maintains status (e.g., requested, scribing, error, scribed), a reference to the template ID, and timing or queue details.

- **recording_session_scribe_result**
  - Stores the final parsed output, categorized by template sections.
  - Typically references the scribe ID and the category ID, along with the output text.

- **parsing_templates**
  - Defines how the final text should be parsed, including instructions, example usage, and rules for formatting.
  - Can be public or private.

- **parsing_template_categories**
  - Splits a template into hierarchical categories (with parent-child relationships), each defining how certain parts of the transcribed text should be interpreted or formatted.
  - Tracks output style, instructions, and an internal path.

- **recording_session_scribe_statuses**
  - Holds possible status values (e.g., requested, scribing, error, scribed) with additional descriptive text.
  - Ensures consistency in naming the different states of the scribe process.

#### Main Process Flow

1. **User Requests a Report**
   - Check if there is an existing transcript that includes all current audio files:
     - If none exists:
       - Create a new transcript record (for the session) and link it to the audio files.
       - Create a scribe record referencing the transcript and a chosen template.
       - For each pending audio file:
         - If the file has no existing queue ID, send a message to the **scribe_v2_transcript_audio_file** queue. Update the audio file record to include queue details.
         - If the file has an existing queue ID, confirm whether it is still in the queue; if not, enqueue it again. Otherwise, do nothing.
     - If a transcript does exist:
       - Check if the transcript’s file path is empty.
         - If it is empty, enqueue a message on **scribe_v2_transcript_recording_session** (to consolidate text).
         - If it is not empty, enqueue a message on **scribe_v2_parse_transcript** (to parse the already available transcript).

2. **SQS Queues and Lambda Processes**
   - **scribe_v2_transcript_audio_file (Transcribe Audio Files)**
     - Receives messages containing a transcript ID and an audio file ID.
     - Retrieves the audio file from storage (S3), then attempts transcription (preferably with a self-hosted Whisper service, otherwise using an external fallback like OpenAI).
     - After successful transcription, uploads the resulting text to S3 and updates the corresponding database records (transcription status, file path, etc.).
     - Checks if all audio files for that transcript are done; if yes, places a message in the **scribe_v2_transcript_recording_session** queue to merge.
     - If transcription succeeds, removes the message from the queue. If an error occurs, updates an error message field in the audio file record.

   - **scribe_v2_transcript_recording_session (Consolidate Transcript)**
     - Receives messages containing a transcript ID.
     - Fetches all transcribed files linked to that transcript, merges or combines their content, then uploads the consolidated text to S3.
     - Optionally, can run an additional step of processing or re-checking if there are any empty or invalid transcriptions.
     - Creates a message for the **scribe_v2_parse_transcript** queue if successful, and updates queue references in the database.
     - On error, stores an error message in the transcript record.

   - **scribe_v2_parse_transcript (Parse and Generate Report)**
     - Receives messages containing a scribe ID.
     - Retrieves the associated transcript and parsing template, then applies any formatting, classification, or segment parsing required.
     - Saves the final parsed output in the database, possibly across multiple categories.
     - If successful, optionally sends an email notification and removes the message from the queue.
     - If there is an error, updates the scribe record to reflect the failure.

#### Additional Considerations

- **Error Handling and DLQs**
  - Each queue should have a Dead Letter Queue (DLQ) for messages that fail processing multiple times.
  - Use the column `queue_error_message` for logging exception details, enabling user-facing feedback or a trigger for reprocessing.

- **Concurrency and Idempotency**
  - Ensure only one process triggers the next phase when multiple audio files finish almost simultaneously.
  - Use flags or transaction checks in the database to prevent double-enqueueing.

- **Scalability**
  - Each SQS queue and Lambda function can scale horizontally.

- **Security**
  - Restrict queue access so only the intended Lambdas can consume messages.
  - Messages should not contain sensitive content; they will only reference IDs.
  - Use presigned URLs for uploading audio files to avoid exposing credentials.

- **Template Versioning and Evolution**
  - Decide how to handle older transcripts linked to a previous template version if a parsing template changes.

- **Fallback and Continuity**
  - Log the usage of self-hosted Whisper and OpenAI to track usage and costs.
  - Introduce an autoscaling feature to manage processing loads for the Whisper service.

#### Backlog Considerations

- **Metrics and Monitoring**
  - Track the number of processed audio files, error counts, and average processing time.

- **Callback or Polling**
  - Notify clients via webhooks, SSE, or polling for status updates.
  - Implement email notifications and real-time status endpoints.

- **Audio Quality Evaluation**
  - Analyze clarity or volume levels of the audio before transcription.

- **Silence Trimming**
  - Automatically remove leading or trailing silence for cost and accuracy improvements.

- **Multi-Language Support**
  - Add capabilities to detect the spoken language and use an appropriate transcription model.

- **Comprehensive Error Handling**
  - Improve logging and enable retries or manual re-queueing for failed tasks.

